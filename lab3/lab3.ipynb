{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def to_screen(name, file):\n",
    "    cv.imshow(name, file)  \n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = 960\n",
    "cy = 540\n",
    "# f = 960\n",
    "f = 1920\n",
    "\n",
    "matrix = np.array([[f, 0, cx], [0, f, cy], [0, 0, 1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = np.array([\n",
    "    [0, 0, 0], \n",
    "    [1, 0, 0], \n",
    "    [1, 1, 0],  \n",
    "    [0, 1, 0],  \n",
    "    [0, 0, 1],  \n",
    "    [1, 0, 1],  \n",
    "    [1, 1, 1],  \n",
    "    [0, 1, 1]   \n",
    "])\n",
    "\n",
    "vertices[:,2] += 5\n",
    "vertices[:,0] += 2\n",
    "\n",
    "edges = np.array([    [0, 1], [1, 2], [2, 3], [3, 0],  \n",
    "    [4, 5], [5, 6], [6, 7], [7, 4],  \n",
    "    [0, 4], [1, 5], [2, 6], [3, 7]   \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneous_coords = vertices @ matrix.T\n",
    "\n",
    "\n",
    "image_coords = homogeneous_coords[:, :2] / homogeneous_coords[:, 2:]\n",
    "image_coords = np.round(image_coords).astype(int)\n",
    "# image_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create empty 1080p image\n",
    "image = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "\n",
    "# draw vertices as green circles\n",
    "for i in range(8):\n",
    "    cv.circle(image, tuple(image_coords[i]), 10, (0, 255, 0), -1)\n",
    "\n",
    "# draw edges as red lines\n",
    "for i, j in edges:\n",
    "    cv.line(image, tuple(image_coords[i]), tuple(image_coords[j]), (0, 0, 255), 2)\n",
    "\n",
    "to_screen(\"cube\", image)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: what happens if you double the focal length?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why only even powers of r are included in this polynomial is because of symmetry. The radial distortion model assumes that the distortion is symmetric with respect to the principal point. \n",
    "\n",
    "Therefore, any odd power of r would introduce an asymmetry in the distortion model that does not exist in reality."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### source: https://learnopencv.com/camera-calibration-using-opencv/\n",
    "\n",
    "import glob\n",
    "\n",
    "pattern_size = (10, 6)\n",
    "\n",
    "objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "calibration_files = glob.glob(\"../calibration_frames/*.png\")\n",
    "\n",
    "for fname in calibration_files:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, corners = cv.findChessboardCorners(gray, pattern_size, None)\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        \n",
    "        cv.drawChessboardCorners(img, pattern_size, corners, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic matrix:\n",
      "[[583.72423649   0.         647.13947331]\n",
      " [  0.         588.20496961 338.38519019]\n",
      " [  0.           0.           1.        ]]\n",
      "Distortion coefficients:\n",
      "[[-2.41188339e-01  6.80055862e-02 -8.82713982e-04 -2.37905310e-05\n",
      "  -9.40313880e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Use the object and image points to estimate camera parameters\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Print the camera matrix and distortion coefficients\n",
    "print(\"Intrinsic matrix:\")\n",
    "print(mtx)\n",
    "print(\"Distortion coefficients:\")\n",
    "print(dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "objpoints = np.array(objpoints)\n",
    "imgpoints = np.array(imgpoints)\n",
    "\n",
    "ret_arr = []\n",
    "mtx_arr = []\n",
    "dist_arr = []\n",
    "rvecs_arr = []\n",
    "tvecs_arr = []\n",
    "\n",
    "for i in range(10):\n",
    "    x = random.randint(len(objpoints), size=(20))\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints[x], imgpoints[x], gray.shape[::-1], None, None)\n",
    "    ret_arr.append( ret)\n",
    "    mtx_arr.append( mtx)\n",
    "    dist_arr.append(dist)\n",
    "    rvecs_arr.append(rvecs)\n",
    "    tvecs_arr.append(tvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533.7214764605827"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation across cx 25.63123709911693\n",
      "standard deviation across cy 19.689454901497086\n",
      "standard deviation across f1 1289.9989956923607\n",
      "standard deviation across f2 601.1873796418492\n"
     ]
    }
   ],
   "source": [
    "# Extract the parameters cx, cy, f1, and f2 from each camera matrix\n",
    "cx_list = [matrix[0, 2] for matrix in mtx_arr]\n",
    "cy_list = [matrix[1, 2] for matrix in mtx_arr]\n",
    "f1_list = [matrix[0, 0] for matrix in mtx_arr]\n",
    "f2_list = [matrix[1, 1] for matrix in mtx_arr]\n",
    "\n",
    "# Calculate the standard deviation of each parameter\n",
    "cx_std = np.std(cx_list)\n",
    "cy_std = np.std(cy_list)\n",
    "f1_std = np.std(f1_list)\n",
    "f2_std = np.std(f2_list)\n",
    "\n",
    "print(f\"standard deviation across cx {cx_std}\")\n",
    "print(f\"standard deviation across cy {cy_std}\")\n",
    "print(f\"standard deviation across f1 {f1_std}\")\n",
    "print(f\"standard deviation across f2 {f2_std}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(mtx_arr)):\n",
    "    img = cv.imread('../calibration_frames/img_0005.png')\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx_arr[i], dist_arr[i], (w,h), 1, (w,h))\n",
    "    # undistort\n",
    "    dst = cv.undistort(img, mtx_arr[i], dist_arr[i], None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    cv.imwrite(f\"calib{i}result.png\", dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "shadow = cv.imread(\"../afbeeldingen/shadow.png\")\n",
    "copy_shadow = shadow.copy()\n",
    "rows, cols = shadow.shape[:2]\n",
    "\n",
    "m = -0.15\n",
    "horizontal_shear_M = np.array([[1, m, 0], [0, 1, 0]], dtype=\"float32\")\n",
    "\n",
    "print(horizontal_shear_M.dtype)\n",
    "\n",
    "# move to the right\n",
    "horizontal_shear_M[0, 2] += 260\n",
    "\n",
    "\n",
    "shear_trans = cv.warpAffine(copy_shadow, horizontal_shear_M, (2*cols, rows))\n",
    "\n",
    "print(shear_trans.dtype)\n",
    "to_screen(\"original_shadow\", shadow)\n",
    "to_screen(\"shear_trans\", shear_trans)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_box = cv.imread(\"../afbeeldingen/shadow_box.png\")\n",
    "\n",
    "# select the 4 corner points as source for getPerspectiveTransform starting from left bove corner and select other points counterwise\n",
    "corner_points = []\n",
    "\n",
    "\n",
    "def onMouse(k, x, y, s, param):\n",
    "    if k == cv.EVENT_LBUTTONDOWN:\n",
    "        param[0] += 1\n",
    "        corner_points.append((x,y))\n",
    "        # print(f\"{x} and {y}\")\n",
    "\n",
    "\n",
    "# create a window\n",
    "cv.namedWindow('klik')\n",
    "\n",
    "\n",
    "aantal = [0]\n",
    "# bind the callback function to window\n",
    "cv.setMouseCallback('klik', onMouse, aantal)\n",
    "\n",
    "\n",
    "cv.imshow('klik', shadow_box)\n",
    "key = cv.waitKey()\n",
    "while (key != 27):\n",
    "    key = cv.waitKey()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(109, 88), (117, 541), (299, 538), (299, 88)]\n",
      "109 and 88\n",
      "117 and 541\n",
      "299 and 538\n",
      "299 and 88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# select the 4 points as dst for getPerspectiveTransform with right upper corner such that the shape is rectangular \n",
    "target_points = corner_points[:3]\n",
    "\n",
    "# width of bottom right point and height of top left point\n",
    "target_points.append((corner_points[2][0], corner_points[0][1]))\n",
    "\n",
    "# test result to see if rectangle\n",
    "img = np.zeros((600,600,3), np.uint8)\n",
    "img_copy = img.copy()\n",
    "print(target_points)\n",
    "for x, y in target_points:\n",
    "    print(f\"{x} and {y}\")\n",
    "    image = cv.circle(img_copy, (x,y), radius=0, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "to_screen(\"img\", img_copy)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.63830727e+00,  7.28028440e-01, -3.95267441e+02],\n",
       "       [ 9.68845187e-03,  5.21407288e+00, -3.19114998e+02],\n",
       "       [ 1.10096044e-04,  6.67916000e-03,  1.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner_np = np.float32(corner_points)\n",
    "target_np = np.float32(target_points)\n",
    "\n",
    "\n",
    "transform_mat = cv.getPerspectiveTransform(np.float32(corner_points), np.float32(target_points))\n",
    "transform_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = cv.warpPerspective(shadow_box,transform_mat,(shadow_box.shape[1], shadow_box.shape[0]))\n",
    "to_screen(\"out\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
